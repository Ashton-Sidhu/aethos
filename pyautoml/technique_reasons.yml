clean:
  general:
    remove_rows: >
      Removed rows because it had too many missing values and those records don't
      contain enough information.

    remove_columns: >
      Removed column column_name_placeholder because it had too many missing values and didn't
      contain enough information.

    remove_duplicate_rows: >
      Removed rows that are exact duplicates of each other and keep only 1 to increase computational performance.
    
    remove_duplicate_columns: >
      Removed columns of which whos values are exact duplicates of each other to reduce redundancy.

    random_discrete: >
      Replaced missing values in column column_name_placeholder with random values that follow the datas distribution,
      as observed in nature, to better simulate the missing data points

  categorical:
    new_category: >
      Replaced missing values in column column_name_placeholder with its own category name because
      the missing values have meaning that should be captured.

    remove_rows: >
      Removed rows that have missing values in column_name_placeholder because column_name_placeholder
      is an important feature and data points with missing data in this column are inconsequential to this problem.

  numeric:
    mean: >
      Replaced missing values in column column_name_placeholder with the average of the values in the column.

    median: >
      Replaced missing values in column column_name_placeholder with the middlemost value in the column.

    mode: >
      Replaced missing values in column column_name_placeholder with the most frequent value in the column.

    constant: >
      Replaced missing values in column column_name_placeholder with the constant.

  text:

preprocess:
  general:
  
  categorical:

  numeric:
    standardize: >
      Standardized the values in column column_name_placeholder between 0 and 1 so all values in every column are in the same
      domain and range does not effect model weights.

  text:
    split_sentence: >
      Text data was split into sentences to be used for futher analysis.

    stem: >
      Stemmed all the words down to their root words for more efficient processing and analysis. For example, words that belong to 
      different tenses are now reduced to the same word, i.e. 'ask' and 'asked'.

feature:
  general:

  categorical:
    onehotencode: >
      Converted the categories in column column_name_placeholder into its own feature where the value is 1 if the category exists
      in the record, 0 otherwise.

  numeric:

  text:
    tfidf: >
      Converted text to a numeric representation where each number represents how important a word(s) is to a corpus. The higher the number,
      the more important words is to the corpus.

    bow: >
      Converted text to a numeric representation where each number represents how many times a word occurs in a sample.

    postag: >
      Tagged each word with its Part of Speech tag where the tag represents whether a word is a Noun, Verb, Adjective, etc.

model:
  text:
    textrank_keywords: >
      Extracted keywords using the Text Rank algorithm.
      
    textrank_summarize: >
      Created an extractive summary using the Text Rank algorithm.
